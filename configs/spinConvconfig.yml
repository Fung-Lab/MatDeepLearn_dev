trainer: property

task:
  # run_mode: train
  identifier: "my_train_job"
  reprocess: False
  parallel: False
  # seed=0 means random initalization
  seed: 0
  # Defaults to run directory if not specified
  #save_dir: 
  continue_job: False
  load_training_state: False
  # Path to the checkpoint file
  #checkpoint_path: 
  write_output: True
  use_amp: True 
  #Training print out frequency (print per n number of epochs)
  

model:
  name: spinconv
  load_model: False
  save_model: True
  model_path: "my_model.pth"
  self_loop: True
  # model attributes
  num_targets: 1
  use_pbc: False
  regress_forces: False
  otf_graph: False
  hidden_channels: 32
  mid_hidden_channels: 256
  num_interactions: 3
  num_basis_functions: 512
  basis_width_scalar: 1.0
  max_num_neighbors: 30
  sphere_size_lat: 12
  sphere_size_long: 8
  cutoff: 6.0
  distance_block_scalar_max: 2.0
  max_num_elements: 100
  embedding_size: 8
  show_timing_info: False
  sphere_message: "fullconv"
  output_message: "fullconv"
  lmax: False
  force_estimator: "random"
  model_ref_number: 0
  readout: "add"
  num_rand_rotations: 5
  scale_distances: True
  num_post_layers: 3
  post_hidden_channels: 64
  pool: "global_mean_pool"
  act: "relu"

optim:
  max_epochs: 400
  max_checkpoint_epochs: 0
  lr: 0.0005
  # Either custom or from torch.nn.functional library. If from torch, loss_type is TorchLossWrapper
  loss:
    loss_type: "TorchLossWrapper"
    loss_args: {"loss_fn": "l1_loss"}
  clip_grad_norm: 10

  batch_size: 40
  optimizer:
    optimizer_type: "AdamW"
    optimizer_args: {}
  scheduler:
    scheduler_type: "ReduceLROnPlateau"
    scheduler_args: {"mode":"min", "factor":0.8, "patience":10, "min_lr":0.00001, "threshold":0.0002}
  verbosity: 5

dataset:
  processed: False
  # Whether to use "inmemory" or "large" format for pytorch-geometric dataset. Reccomend inmemory unless the dataset is too large
  # dataset_type: "inmemory"
  # Path to data files
  src: "/global/cfs/projectdirs/m3641/Shared/Materials_datasets/MP_data_69K/data.json"
  #src: "/project/Rithwik/2D_data_npj/raw/"
  #src: "/project/Rithwik/QM9/data.json"
  src: "/storage/coda1/p-vfung3/0/rseth34/MP_data_69K/data.json"
  #Path to target file within data_path
  #target_path: "/global/cfs/projectdirs/m3641/Shared/Materials_datasets/2D_data_npj/targets.csv"
  #target_path: "/project/Rithwik/MP_data_69K/targets.csv"
  target_path:
  # Path to save processed data.pt file
  #pt_path: "/global/cfs/projectdirs/m3641/Rithwik/datasets/MP_data_69K/"
  pt_path: "/storage/coda1/p-vfung3/0/rseth34/MP_data_69K/"
  prediction_level: "graph"

  transforms:
    - name: GetY
      args:
        index: 0
      otf: True # Optional parameter, default is False
  all_neighbors : True
  # one of mdl, ase, ocp
  edge_calc_method: "mdl"
  # Format of data files (limit to those supported by ASE)
  data_format: "json"
  # Method of obtaining atom idctionary: available:(onehot)
  node_representation: "onehot"
  additional_attributes: []
  # Print out processing info
  verbose: True
  # Index of target column in targets.csv
  # graph specific settings
  preprocess_params:
    # one of mdl (minimum image convention), ocp (all neighbors included)
    edge_calc_method: "mdl" 
    # determine if edges are computed, if false, then they need to be computed on the fly   
    preprocess_edges: True
    # determine if edge attributes are computed during processing, if false, then they need to be computed on the fly   
    preprocess_edge_features: True
    # determine if node attributes are computed during processing, if false, then they need to be computed on the fly   
    preprocess_nodes: True
    cutoff_radius : 8.0
    n_neighbors : 250
    num_offsets: 2
    edge_steps : 50
    self_loop: True
    # Method of obtaining atom dictionary: available: (onehot)
    node_representation: "onehot"    
    all_neighbors: True
  # Ratios for train/val/test split out of a total of 1
  train_ratio: 0.9
  val_ratio: 0.05
  test_ratio: 0.05
