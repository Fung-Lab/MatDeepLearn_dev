trainer: property

task:
    # run_mode: train
    identifier: 'rt_2dnpj'
    reprocess: False
    run_id: ''
    parallel: False
    device: 'cuda:0'
    seed: 0
    # seed=0 means random initalization
    write_output: True
    # Training print out frequency (print per n number of epochs)
    verbosity: 1
    wandb:
        use_wandb: True
        wandb_entity: 'fung-lab'
        wandb_project: 'rt'
        notes: 'try MP dataset'
        tags: ['test']
        track_params:
            - 'optim.lr'
            - 'optim.batch_size'
            - 'optim.max_epochs'
            - 'dataset.preprocess_params.num_offsets'
            - 'dataset.preprocess_params.edge_calc_method'
            - 'dataset.preprocess_params.all_neighbors'
            - 'dataset.preprocess_params.edge_steps'
            - 'dataset.preprocess_params.use_degree'
        log_artifacts:
            # - "/Users/sidbaskaran/Desktop/research/MatDeepLearn_dev/matdeeplearn/models/rt/model.py"
            - '/nethome/sbaskaran31/projects/Sidharth/MatDeepLearn_dev/matdeeplearn/models/rt/model.py'
            # - "/global/cfs/projectdirs/m3641/Sidharth/MatDeepLearn_dev/matdeeplearn/models/rt/model.py"
        metadata:
            architecture: 'RTModel'
            cluster: 'fung-cluster'
            dataset: 'MP_data_69K'
        sweep:
            parallel: True
            do_sweep: False # ignore rest of config if False
            system: 'phoenix_slurm' # one of "local", "phoenix_slurm"
            job_config: '/nethome/sbaskaran31/projects/Sidharth/MatDeepLearn_dev/configs/jobs/phoenix_slurm.yml'
            count: 3
            sweep_file: '/nethome/sbaskaran31/projects/Sidharth/MatDeepLearn_dev/configs/sweeps/cgcnn_vn_sweep_d1.yml'

model:
    name: RTModel
    load_model: False
    save_model: True
    model_path: 'rt.pth'
    # model hyperparams
    hyperparams:
        node_dim_proj: 128
        edge_dim_proj: 64
        node_hidden: 256
        edge_hidden_1: 384
        edge_hidden_2: 128
        heads: 64
        layers: 64
        dropout: 0.1
        disable_edge_updates: False
        node_level_output: False
        edge_level_output: False

optim:
    max_epochs: 250
    lr: 0.002
    verbosity: 1
    loss:
        loss_type: 'TorchLossWrapper'
        loss_args: { 'loss_fn': 'l1_loss' }
    batch_size: 256
    optimizer:
        optimizer_type: 'AdamW'
        optimizer_args:
            betas: [0.9, 0.98]
            eps: 0.000000001
    scheduler:
        step: 'step' # "epoch" or "step"
        scheduler_type: 'LambdaLR'
        scheduler_args:
            { 'batch_size': 256, 'num_examples': 3051, 'warmup_steps': 1500, 'epochs': 250 }

dataset:
    processed: False # if False, need to preprocessor data and generate .pt file
    force_preprocess: False
    num_examples: 0 # set to 0 when using full dataset, else will take the first "num_examples" examples
    # Path to data files
    # src: "/Users/sidbaskaran/Desktop/research/2D_data_npj/raw"
    src: '/nethome/sbaskaran31/projects/Sidharth/2D_data_npj/raw'
    # src: "/global/cfs/projectdirs/m3641/Sidharth/datasets/2D_data_npj/raw"
    # target_path: "/Users/sidbaskaran/Desktop/research/2D_data_npj/targets.csv"
    target_path: '/nethome/sbaskaran31/projects/Sidharth/2D_data_npj/targets.csv'
    # target_path: "/global/cfs/projectdirs/m3641/Sidharth/datasets/2D_data_npj/targets.csv"
    # pt_path: "/Users/sidbaskaran/Desktop/research/2D_data_npj/processed/ocp"
    pt_path: '/nethome/sbaskaran31/projects/Sidharth/2D_data_npj/processed/ocp'
    # pt_path: "/global/cfs/projectdirs/m3641/Sidharth/datasets/2D_data_npj/processed/ocp"
    # transforms
    transforms:
        - name: GetY
          args:
              index: 0
          otf: False
        - name: RTTransform
          args:
              max_nodes: 12 # determine through observation
    # use for passing into global config
    # one of MDL, ASE, OCP
    use_sweep_params: False
    apply_pre_transform_processing: True
    # use again for passing into global config
    data_format: 'json'
    node_representation: 'onehot'
    additional_attributes: []
    # Print out processing info
    verbose: True
    # graph specific settings: preprocessing hyperparams
    preprocess_params:
        cutoff_radius: 5.0
        n_neighbors: 250
        process_batch_size: 25
        edge_calc_method: 'ocp'
        num_offsets: 1
        edge_steps: 25
        all_neighbors: True
        use_degree: False
    # Ratios for train/val/test split out of a total of 1
    train_ratio: 0.8
    val_ratio: 0.05
    test_ratio: 0.15
