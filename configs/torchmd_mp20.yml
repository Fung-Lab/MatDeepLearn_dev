trainer: property

task:
  #run_mode: train
  identifier: my_train_job
  parallel: False
  # If seed is not set, then it will be random every time
  seed: 12345678
  # Defaults to run directory if not specified
  save_dir: 
  # continue from a previous job
  continue_job: False
  # spefcify if the training state is loaded: epochs, learning rate, etc
  load_training_state: False
  # Path to the checkpoint.pt file
  checkpoint_path: 
  # Whether to write predictions to csv file. E.g. ["train", "val", "test"]
  write_output: [val, test]
  # Frequency of writing to file; 0 denotes writing only at the end, 1 denotes writing every time
  output_frequency: 0
  # Frequency of saving model .pt file; 0 denotes saving only at the end, 1 denotes saving every time, -1 denotes never saving; this controls both checkpoint and best_checkpoint
  model_save_frequency: 0
  # Specify if labels are provided for the predict task
  # labels: True
  # Use amp mixed precision
  use_amp: True

model:
  name: torchmd_etEarly
  # model attributes
  hidden_channels: 128
  num_filters: 128
  num_layers: 8
  num_rbf: 50
  rbf_type: "expnorm"
  trainable_rbf: True
  activation: "silu"
  attn_activation: "silu"
  num_heads: 8
  distance_influence: "both"
  neighbor_embedding: True
  cutoff_lower: 0.0
  cutoff_upper: 8.0
  max_z: 100
  max_num_neighbors: 32
  aggr: "add"
  num_post_layers: 2
  post_hidden_channels: 128
  pool: "global_add_pool"
  # Compute edge indices on the fly in the model forward
  otf_edge_index: True 
  # Compute edge attributes on the fly in the model forward
  otf_edge_attr: True 
  # Compute node attributes on the fly in the model forward
  otf_node_attr: False
  # compute gradients w.r.t to positions and cell, requires otf_edge_attr=True      
  gradient: True

optim:
  batch_size: 32
  max_epochs: 200
  max_checkpoint_epochs: 0
  lr: 0.0002
  # Either custom or from torch.nn.functional library. If from torch, loss_type is TorchLossWrapper
  loss:
    # loss_type: "TorchLossWrapper"
    # loss_args: {"loss_fn": "l1_loss"}
    # loss_type: "ForceStressLoss"
    # loss_args: {"weight_energy": 0, "weight_force": 1, "weight_stress": 0}
    #loss_type: "ForceLoss"
    #loss_args: {"weight_energy": 1.0, "weight_force": 1.0}
    loss_type: "NoisyNodeLoss"
    loss_args: {"weight_energy": 0.0, "weight_noise": 1.0}
  clip_grad_norm: 10
  optimizer:
    optimizer_type: "AdamW"
    optimizer_args: {}
  scheduler:
    scheduler_type: "ReduceLROnPlateau"
    scheduler_args: {"mode":"min", "factor":0.8, "patience":10, "min_lr":0.000001, "threshold":0.0002}
  #Training print out frequency (print per n number of epochs)
  verbosity: 1
  # tdqm progress bar per batch in the epoch
  batch_tqdm: True

dataset:
  name: "test_data"
  processed: False
  # Path to data files - this can either be in the form of a string denoting a single path or a dictionary of {train: train_path, val: val_path, test: test_path, predict: predict_path}
  src:
    train: /storage/home/hcoda1/5/sjia65/p-vfung3-0/Shared/Materials_datasets/CDVAE/mp_20/raw_train/
    val: /storage/home/hcoda1/5/sjia65/p-vfung3-0/Shared/Materials_datasets/CDVAE/mp_20/raw_val/
    test: /storage/home/hcoda1/5/sjia65/p-vfung3-0/Shared/Materials_datasets/CDVAE/mp_20/raw_test/
  # src: /storage/home/hcoda1/5/sjia65/p-vfung3-0/Shared/Materials_datasets/MP_data_forces/raw/data_relaxed.json
  # Path to target file within data_path - this can either be in the form of a string denoting a single path or a dictionary of {train: train_path, val: val_path, test: test_path} or left blank when the dataset is a single json file
  # Example: target_path: "data/test_data/raw_graph_scalar/targets.csv"
  target_path:
    train: /storage/home/hcoda1/5/sjia65/p-vfung3-0/Shared/Materials_datasets/CDVAE/mp_20/raw_train/targets.csv
    val: /storage/home/hcoda1/5/sjia65/p-vfung3-0/Shared/Materials_datasets/CDVAE/mp_20/raw_val/targets.csv
    test: /storage/home/hcoda1/5/sjia65/p-vfung3-0/Shared/Materials_datasets/CDVAE/mp_20/raw_test/targets.csv
  # Path to save processed data.pt file
  pt_path: "data/carbon/"
  # Either "node" or "graph"
  prediction_level: "graph"

  transforms:
    - name: NoisyNode
      args:
        std: 0.1
      otf_transform: True
    - name: GetY
      args:
        # index specifies the index of a target vector to predict, which is useful when there are multiple property labels for a single dataset
        # For example, an index: 0 (default) will use the first entry in the target vector
        # if all values are to be predicted simultaneously, then specify index: -1
        index: -1
      otf_transform: True # Optional parameter, default is False
  # Format of data files (limit to those supported by ASE: https://wiki.fysik.dtu.dk/ase/ase/io/io.html)
  data_format: "cif"
  #additional_attributes: ["forces"]
  # additional_attributes: ["forces", "stress"]
  #additional_attributes:
  # Print out processing info
  verbose: True
  # Index of target column in targets.csv
  # graph specific settings
  preprocess_params:
    # one of mdl (minimum image convention), ocp (all neighbors included)
    edge_calc_method: ocp 
    # determine if edges are computed, if false, then they need to be computed on the fly   
    preprocess_edges: False
    # determine if edge attributes are computed during processing, if false, then they need to be computed on the fly   
    preprocess_edge_features: False
    # determine if node attributes are computed during processing, if false, then they need to be computed on the fly   
    preprocess_node_features: True
    cutoff_radius : 8.0
    n_neighbors : 250
    num_offsets: 2
    # dimension of node attributes
    node_dim : 100
    # dimension of edge attributes
    edge_dim : 50
    self_loop: True
    # Method of obtaining atom dictionary: available: (onehot)
    node_representation: onehot    
    all_neighbors: True
  # Number of workers for dataloader, see https://pytorch.org/docs/stable/data.html
  num_workers: 0
  # Where the dataset is loaded; either "cpu" or "cuda"
  dataset_device: cpu
  # Ratios for train/val/test split out of a total of less than 1
  train_ratio: 0.8
  val_ratio: 0.05
  test_ratio: 0.15

