Single dataset found at data/test_data/data_graph_scalar.json
Processing device: cpu
Reading one JSON file for multiple structures.
Loading json file as dict (this might take a while for large json file size).
Converting data to standardized form for downstream processing.
Getting torch_geometric.data.Data() objects.
Generating node features...
Generating edge features...
Applying transforms.
Processed data saved successfully.
Loading dataset to cpu
Using PyTorch automatic mixed-precision
GPU is available: False, Quantity: None
Dataset(s) used:
Dataset length: ('train', 800)
Dataset length: ('val', 50)
Dataset length: ('test', 150)
Data(n_atoms=[1], pos=[10, 3], cell=[1, 3, 3], structure_id=[1], z=[10], u=[1, 3], y=[1, 1], edge_index=[2, 90], edge_weight=[90], edge_vec=[90, 3], cell_offsets=[90, 3], neighbors=[0], x=[10, 100], edge_attr=[90, 50])
tensor(78)
tensor([-41.0815])

--------------------------------------------------------------------------
               Layer.Parameter    Param Tensor Shape              Param #
--------------------------------------------------------------------------
         pre_lin_list.0.weight            [100, 100]                10000
           pre_lin_list.0.bias                 [100]                  100
      conv_list.0.lin_f.weight            [100, 250]                25000
        conv_list.0.lin_f.bias                 [100]                  100
      conv_list.0.lin_s.weight            [100, 250]                25000
        conv_list.0.lin_s.bias                 [100]                  100
      conv_list.1.lin_f.weight            [100, 250]                25000
        conv_list.1.lin_f.bias                 [100]                  100
      conv_list.1.lin_s.weight            [100, 250]                25000
        conv_list.1.lin_s.bias                 [100]                  100
      conv_list.2.lin_f.weight            [100, 250]                25000
        conv_list.2.lin_f.bias                 [100]                  100
      conv_list.2.lin_s.weight            [100, 250]                25000
        conv_list.2.lin_s.bias                 [100]                  100
      conv_list.3.lin_f.weight            [100, 250]                25000
        conv_list.3.lin_f.bias                 [100]                  100
      conv_list.3.lin_s.weight            [100, 250]                25000
        conv_list.3.lin_s.bias                 [100]                  100
              bn_list.0.weight                 [100]                  100
                bn_list.0.bias                 [100]                  100
              bn_list.1.weight                 [100]                  100
                bn_list.1.bias                 [100]                  100
              bn_list.2.weight                 [100]                  100
                bn_list.2.bias                 [100]                  100
              bn_list.3.weight                 [100]                  100
                bn_list.3.bias                 [100]                  100
        post_lin_list.0.weight            [150, 100]                15000
          post_lin_list.0.bias                 [150]                  150
        post_lin_list.1.weight            [150, 150]                22500
          post_lin_list.1.bias                 [150]                  150
        post_lin_list.2.weight            [150, 150]                22500
          post_lin_list.2.bias                 [150]                  150
                lin_out.weight              [1, 150]                  150
                  lin_out.bias                   [1]                    1
--------------------------------------------------------------------------
Total params: 272301
Trainable params: 272301
Non-trainable params: 0
Settings: 
{'dataset': {'additional_attributes': None,
             'data_format': 'json',
             'dataset_device': 'cpu',
             'name': 'test_data',
             'num_workers': 0,
             'prediction_level': 'graph',
             'preprocess_params': {'cutoff_radius': 8.0,
                                   'edge_calc_method': 'mdl',
                                   'edge_dim': 50,
                                   'n_neighbors': 250,
                                   'node_dim': 100,
                                   'node_representation': 'onehot',
                                   'num_offsets': 2,
                                   'preprocess_edge_features': True,
                                   'preprocess_edges': True,
                                   'preprocess_node_features': True,
                                   'self_loop': True},
             'processed': False,
             'pt_path': 'data/',
             'src': 'data/test_data/data_graph_scalar.json',
             'target_path': None,
             'test_ratio': 0.15,
             'train_ratio': 0.8,
             'transforms': [{'args': {'index': -1},
                             'name': 'GetY',
                             'otf_transform': True}],
             'val_ratio': 0.05,
             'verbose': True},
 'model': {'act': 'relu',
           'batch_norm': True,
           'batch_track_stats': True,
           'dim1': 100,
           'dim2': 150,
           'dropout_rate': 0.0,
           'gc_count': 4,
           'gradient': False,
           'model_ensemble': 3,
           'name': 'CGCNN',
           'otf_edge_attr': False,
           'otf_edge_index': False,
           'otf_node_attr': False,
           'pool': 'global_add_pool',
           'pool_order': 'early',
           'post_fc_count': 3,
           'pre_fc_count': 1,
           'prediction_level': 'graph'},
 'optim': {'batch_size': 100,
           'batch_tqdm': False,
           'clip_grad_norm': 10,
           'loss': {'loss_args': {'loss_fn': 'l1_loss'},
                    'loss_type': 'TorchLossWrapper'},
           'lr': 0.001,
           'max_checkpoint_epochs': 0,
           'max_epochs': 2,
           'optimizer': {'optimizer_args': {}, 'optimizer_type': 'AdamW'},
           'scheduler': {'scheduler_args': {'factor': 0.8,
                                            'min_lr': 1e-05,
                                            'mode': 'min',
                                            'patience': 10,
                                            'threshold': 0.0002},
                         'scheduler_type': 'ReduceLROnPlateau'},
           'verbosity': 5},
 'submit': False,
 'task': {'checkpoint_path': None,
          'continue_job': False,
          'identifier': 'my_train_job',
          'load_training_state': False,
          'log_id': '2024-01-04-19-24-12-612',
          'model_save_frequency': 0,
          'output_frequency': 0,
          'parallel': False,
          'run_mode': 'train',
          'save_dir': None,
          'seed': 12345678,
          'use_amp': True,
          'write_output': ['train', 'val', 'test']},
 'trainer': 'property'}
Starting regular training
running for 2 epochs on list model
Epoch: 0000, Learning Rate: 0.001000, Training Error: 35.15119, Val Error: 30.77588, Time per epoch (s): 2.48466
Final Losses: 
Saved train error: 31.50680
Saved val error: 30.77588
